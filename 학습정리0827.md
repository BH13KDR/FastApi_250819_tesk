###[심화 개념 : INDEX]
인덱스(Index)의 정의:
데이터베이스에서 원하는 데이터를 더 빠르게 찾기 위해 사용하는 자료구조.
도서관의 책장 분류 "찾아보기(Index)"의 역할을 함

특징

장점 : 조회(SELECT) 성능을 크게 향상시킴

단점 : 데이터 삽입/수정/삭제(INSERT/UPDATE/DELETE) 는 느려질 수 있음
→ 인덱스도 함께 갱신해야 하기 때문

메모리 캐싱을 통해 디스크 I/O를 최소화하여 속도를 높임

주로 B+ Tree 자료구조를 사용함 (MySQL, PostgreSQL 등)

[데이터베이스 vs 파일 시스템]

| 항목          | 파일 I/O                  | 데이터베이스(DB)                  |
| ----------- | ----------------------- | --------------------------- |
| **조회 속도**   | 파일 전체를 순회해야 함 (느림)      | 인덱스로 필요한 부분만 빠르게 탐색 (빠름)    |
| **동시성**     | 여러 프로그램이 동시에 접근 시 충돌 가능 | 트랜잭션(Transaction)으로 안전하게 관리 |
| **데이터 일관성** | 보장하기 어려움                | ACID 트랜잭션으로 보장              |
| **분산 처리**   | 서버마다 데이터가 흩어짐           | DBMS에서 일관되게 관리 가능           |

[인덱스가 빠른 이유]
① 메모리 캐싱

인덱스는 처음 디스크에 저장되지만,

한 번 조회되면 메모리 버퍼 풀(Buffer Pool) 에 올라와 캐싱됨.

이후 동일한 쿼리 시 메모리에서 바로 조회 → 디스크 접근 최소화.

② 자료구조: B+ Tree

대부분의 RDBMS(MySQL, PostgreSQL 등)는 B+ Tree 인덱스를 사용합니다.

B+ Tree 구조의 특징 :

데이터는 리프 노드(leaf node)에만 저장

리프 노드들이 연결 리스트로 연결되어 있어 범위 검색(Range Query) 에 강함.

중간 노드는 탐색 경로만 제공 → 트리 높이가 낮아 탐색 속도 ↑

| 특징          | B Tree               | B+ Tree             |
| ----------- | -------------------- | ------------------- |
| 데이터 저장 위치   | 모든 노드에 저장 가능         | 리프 노드에만 저장          |
| 범위 검색 속도    | 느림 (계속 트리 탐색 필요)     | 빠름 (리프 노드 순회만 하면 됨) |
| 단건 조회       | B Tree가 조금 더 빠를 수 있음 | 약간 느릴 수 있음          |
| MySQL 기본 구조 | ❌                    | ✅                   |


[MySQL 인덱스 생성과 관리]
4.1 단일 인덱스 생성
```sql
CREATE TABLE students (
    id INT AUTO_INCREMENT PRIMARY KEY,
    name VARCHAR(100) NOT NULL,
    score INT NOT NULL,
    INDEX idx_score (score)   -- score 컬럼 인덱스 추가
);
```

[복합 인덱스 (Composite Index)]

여러 컬럼을 묶어서 하나의 인덱스로 생성.
```sql
ALTER TABLE students ADD INDEX idx_score_name (score, name);
```
복합 인덱스 특징 :

왼쪽 우선 원칙(Leftmost Prefix Rule)
→ 인덱스 정의 순서가 검색 성능을 결정.

(score, name) 복합 인덱스 예시:

```sql
-- ✅ 
WHERE score = 90 AND name = 'Tom' -- → 인덱스 사용 가능
-- ✅ 
WHERE score = 90 -- → 인덱스 사용 가능
-- ❌ 
WHERE name = 'Tom' -- → 인덱스 미사용
→ name 단독 인덱스를 따로 추가 필요
```

[인덱스 삭제]
```sql
ALTER TABLE students DROP INDEX idx_score;
```

[쿼리 플랜 분석 (EXPLAIN / ANALYZE)]

쿼리 실행 계획 확인
```sql
EXPLAIN ANALYZE SELECT * FROM students WHERE score > 85;
```

EXPLAIN → 쿼리 실행 계획 요약

EXPLAIN ANALYZE → 실제 실행 시간, 쿼리 비용 등 더 상세한 정보 제공
!!!INDEX고칠 때마다 체크하자!!!

[Scan 종류]

| Scan 방식              | 설명         | 성능   | 인덱스 사용 여부 |
| -------------------- | ---------- | ---- | --------- |
| **Index Range Scan** | 인덱스 일부만 읽음 | ✅ 빠름 | ✅ 사용      |
| **Index Full Scan**  | 인덱스 전체를 읽음 | ⚡ 보통 | ✅ 사용      |
| **Table Full Scan**  | 테이블 전체를 읽음 | ❌ 느림 | ❌ 미사용     |

Tip: 테이블이 크면 Table Full Scan은 장애로 이어질 수 있으므로 주의!

[Covered Query (커버링 인덱스)]

정의: 인덱스에 포함된 컬럼만으로 쿼리를 처리할 수 있는 경우.
```sql
SELECT score FROM students WHERE score > 90;
```

score 컬럼에 인덱스가 걸려있다면 테이블 접근 없이 인덱스만으로 결과 반환

디스크 I/O 최소화 → 매우 빠른 성능

[EdgeDB에서의 인덱스]

EdgeDB에서는 Python 스타일 Schema에서 인덱스를 정의할 수 있음.
```python
module default {
    type Person {
        required name: str;
    }

    type Movie {
        title: str;
        multi actors: Person;
        index on (.title);  # title 컬럼 인덱스 추가
    }
}
```

[EdgeDB 인덱스 사용 여부 확인
```bash
edgedb analyze 'select default::Movie {id, title} filter .title = "a"' --expand
```

| 결과            | 의미         | MySQL과 비교        |
| ------------- | ---------- | ---------------- |
| **SeqScan**   | 테이블 전체를 스캔 | Table Full Scan  |
| **IndexScan** | 인덱스 활용     | Index Range Scan |

[INSERT와 인덱스]

INSERT 성능은 인덱스 갯수에 비례해 느려짐.

인덱스가 많을수록, 데이터를 삽입할 때 모든 인덱스를 갱신해야 하기 때문.

따라서 읽기(SELECT) 중심 시스템 → 인덱스 적극 활용
쓰기(INSERT/UPDATE) 중심 시스템 → 인덱스 최소화 필요

[인덱스 최적화 전략]
인덱스를 써야 하는 경우

①자주 검색, 정렬, JOIN에 사용되는 컬럼

②범위 검색(BETWEEN, >, <)에 자주 쓰이는 컬럼

③WHERE 조건문에 자주 등장하는 컬럼

[인덱스를 쓰지 않는 게 좋은 경우]

①데이터 변경이 매우 빈번한 컬럼

②데이터가 매우 적은 테이블 (Table Full Scan이 더 빠를 수 있음)

③카디널리티(값의 다양성)가 낮은 컬럼
→ 예: 성별, Y/N, 국가코드 등

| 개념                    | 설명                                  | 예시                            |
| --------------------- | ----------------------------------- | ----------------------------- |
| **Index**             | 데이터를 빠르게 찾기 위한 자료구조                 | `INDEX idx_score(score)`      |
| **Composite Index**   | 여러 컬럼을 묶은 인덱스                       | `(score, name)`               |
| **EXPLAIN / ANALYZE** | 쿼리 실행 계획 확인                         | `EXPLAIN ANALYZE`             |
| **Scan 종류**           | Index Range, Index Full, Table Full | 성능 차이 큼                       |
| **Covered Query**     | 인덱스만으로 처리 가능                        | `SELECT score WHERE score>90` |
| **B+ Tree**           | MySQL 기본 인덱스 구조                     | 범위 검색 강점                      |
| **EdgeDB Index**      | EdgeDB에서 인덱스 생성                     | `index on (.title)`           |




###[심화 개념 : pyproject.toml vs poetry.lock]

| 구분           | **pyproject.toml**                | **poetry.lock**                |
| ------------ | --------------------------------- | ------------------------------ |
| **역할**       | 어떤 패키지를 **어떤 범위**로 쓸지 정의          | 실제 **설치된 패키지의 정확한 버전** 명시      |
| **버전 지정 방식** | 범위 지정 가능 (`^`, `~`, `>=`, `==` 등) | 단일 버전으로 고정 (`0.104.1` 등)       |
| **관리 주체**    | 사람이 작성 또는 수정                      | Poetry가 자동 생성 및 관리             |
| **목적**       | **정책**을 정의                        | **환경 재현성(Reproducibility)** 보장 |

pyproject.toml → 원하는 범위의 정책 정의

poetry.lock → 실제로 설치된 정확한 버전 기록

팀 개발에서는 poetry.lock 커밋이 필수

[Poetry 버전 스펙 (Version Spec)]

(1) 버전 명시 방법
| 예시                      | 의미                                        |
| ----------------------- | ----------------------------------------- |
| `fastapi = "0.115.6"`   | **정확히 0.115.6 버전만** 설치                    |
| `fastapi = "^0.115.6"`  | `>=0.115.6` **AND** `<1.0.0` (하위 호환 유지)   |
| `fastapi = "~0.115.6"`  | `>=0.115.6` **AND** `<0.116.0` (패치 범위에서만) |
| `fastapi = ">=0.115.6"` | 0.115.6 이상 최신 버전                          |
| `fastapi = "*" `        | 아무 버전이나 설치 가능 (**권장 안 함**)                |

(2) ^ 연산자의 핵심 의미
```toml
fastapi = "^0.115.6"
```

"0.115.6 이상" 이면서 "다음 메이저(1.0.0) 전까지" 버전 허용

이유: 메이저 버전이 바뀌면 하위 호환성이 깨질 가능성이 높기 때문

Poetry는 poetry update 시 이 범위 안에서 가장 최신 버전으로 갱신

[SemVer 규칙 (Semantic Versioning)]

버전 표기: MAJOR.MINOR.PATCH

| 항목        | 의미                     | 예시              | 하위 호환성      |
| --------- | ---------------------- | --------------- | ----------- |
| **MAJOR** | API 변경, 기존 코드 깨질 수 있음  | `1.0.0 → 2.0.0` | ❌ 깨질 가능성 높음 |
| **MINOR** | 새로운 기능 추가, 기존 기능 영향 없음 | `1.2.0 → 1.3.0` | ✅ 호환 유지     |
| **PATCH** | 버그 수정, 보안 패치           | `1.2.1 → 1.2.2` | ✅ 호환 유지     |


(1) 하위 호환성(Backward Compatibility) 예제
❌ 호환성 깨진 경우
```python
def add_ints(a: int, b: int, c: int) -> int:
    return a + b + c
```
```python
print(add_ints(1, 3))  # ❌ TypeError 발생
```

✅ 호환성 유지하는 방법
```python
def add_ints(a: int, b: int, *args: int) -> int:
    return sum((a, b, *args))

print(add_ints(1, 3))        # 4
print(add_ints(1, 3, 5, 7))  # 16
```
*새 기능을 추가하더라도 기존 클라이언트 코드가 동작해야 함

*라이브러리 개발 시 SemVer 규칙을 반드시 준수해야 함

[poetry.lock의 중요성]
(1) poetry.lock 역할

설치된 정확한 버전을 기록 → 팀원 모두 동일한 환경 보장.

의존성 충돌을 방지한다.

CI/CD 환경에서 재현성 보장

예시:
```toml
[[package]]
name = "fastapi"
version = "0.104.1"  # 고정
description = "FastAPI framework"
files = [
    {file = "fastapi-0.104.1-py3-none-any.whl", hash = "..."},
]
```

(2) poetry.lock 관리 팁

| 상황               | 명령어                                      | 설명                |
| ---------------- | ---------------------------------------- | ----------------- |
| 새로운 패키지 설치       | `poetry add fastapi`                     | toml + lock 자동 갱신 |
| 기존 패키지 업데이트      | `poetry update fastapi`                  | lock 버전 갱신        |
| 전체 패키지 최신화       | `poetry update`                          | toml 범위 내에서 최신화   |
| lock 파일 삭제 후 재생성 | `poetry lock --no-update`                | 설치 버전 그대로 다시 생성   |
| lock 무시하고 설치     | `poetry install --no-root --without dev` | lock 무시 가능하지만 비권장 |

[실무 팁]
(1) lock 파일 커밋 필수

팀 프로젝트에서는 반드시 poetry.lock을 깃에 커밋해야 함

이유:

팀원이 poetry install 하면 동일한 버전 설치

배포 환경(CI/CD)에서도 동일한 환경 보장

(2) 업데이트 전략
안정성 중시
```bash
poetry install
```
lock 파일에 기록된 버전 그대로 설치 → 안정적

최신 기능 필요할 때
```bash
poetry update fastapi
```

toml 범위 안에서 최신 버전으로 업데이트

lock 파일 자동 갱신

(3) 문제 상황 예시

상황: 팀원이 poetry.lock을 삭제하고 poetry install

toml에 ^0.115.6로 되어 있으므로 최신 0.115.x 버전 설치

기존 개발 환경과 버전 불일치 → 버그 발생 가능

해결책:

poetry.lock을 절대 삭제하지 말고 커밋 관리

[정리 다이어그램]
```
[pyproject.toml]
   ↓  (버전 정책)
fastapi = "^0.115.6"
   ↓  (설치)
poetry install
   ↓
[poetry.lock]
fastapi = "0.115.8"  ← 실제 설치 버전 고정
```

[핵심 요약]

pyproject.toml → 정책: “어떤 범위의 버전을 쓸지”

poetry.lock → 결과: “실제로 어떤 버전을 썼는지”

^는 하위 호환성 유지 범위에서 최신 버전 설치

MAJOR.MINOR.PATCH → SemVer 규칙 엄격히 지키기

팀 프로젝트에서는 poetry.lock 반드시 커밋

CI/CD에서도 lock 기반으로 설치 → 재현성 확보







###[Python Asyncio & Event Loop]

[코루틴(Coroutine)과 Generator 비교]

| 특징    | Generator                     | Coroutine                       |
| ----- | ----------------------------- | ------------------------------- |
| 정의    | `def` + `yield`               | `async def`                     |
| 호출    | 함수 호출 → Generator 객체 반환       | 함수 호출 → Coroutine 객체 반환         |
| 실행 흐름 | `yield`에서 일시정지 후 `next()`로 재개 | `await`에서 일시정지 후 Future 완료 시 재개 |
| 사용    | 반복 처리, 지연 계산 등                | 비동기 처리, I/O 병렬 처리 등             |


await 는 Generator의 yield와 유사하게 “실행을 일시정지”시키고 이벤트 루프에 제어를 넘깁니다.

Coroutine은 Generator와 달리 이벤트 루프(event_loop)가 필요하며, 이벤트 루프가 스케줄링을 관리합니다.

[이벤트 루프(Event Loop)]
왜 써야하나?

기본적으로 동기(Synchronous)방식으로 작동하는 파이썬의 경우,
Timesleep등 지연이 필요한부분에서 연산과 시간 낭비가 발생.

이를 해결하는 방법중 하나가 asyncio (비동기 + 이벤트 루프) 방식.

낭비가 발생시 코루틴을 잠시 멈추고 이벤트 루프에 제어권 반환해,
다른 대기 중인 작업으로 전환 → CPU 낭비 없음.

asyncio + 이벤트 루프 =
"스레드 없이도 수천 개 I/O 작업을 동시에 처리하는 기술"

네트워크, DB, 파일 I/O 등 대기 시간이 많은 작업에서 필수

FastAPI, 웹크롤러, 실시간 게임 서버, 채팅 시스템 등에서 널리 사용

[이벤트 루프(Event Loop)의 주요 역할]

코루틴(Task)을 등록,
실행 가능 상태 관리

Future, TimerHandle, Task 스케줄링

주요 내부 구조

_ready: 즉시 실행 가능한 Task/Handle을 저장하는 deque
    → 바로 실행 가능
_scheduled: 미래 시점에 실행될 TimerHandle을 저장하는 heap (우선순위 큐)
    → 시간 조건 충족 시 _ready로 이동

Task, Future, Coroutine 모두 이벤트 루프를 통해 실행됩니다.

_ready가 비어있으면 이벤트 루프는 _scheduled에서 시간이 지난 Handle을 옮겨서 실행.

[asyncio 기초 사용법]
① 코루틴 정의
```python
import asyncio

async def hi(sleep_time, message):
    print(f"start {message}")
    await asyncio.sleep(sleep_time)
    print(f"end {message}")
```

② 코루틴 실행

#단일 코루틴 실행
```python
asyncio.run(hi(1, "Hello"))
```
#여러 코루틴 병렬 실행
```python
async def main():
    coros = [hi(i, str(i)) for i in range(1, 6)]
    await asyncio.gather(*coros)

asyncio.run(main())
```

③ Task와 Future

Task: 코루틴을 이벤트 루프에 등록해서 실행하도록 감싼 객체

Future: 나중에 값이 들어올 약속 객체

await는 Future가 완료될 때까지 실행을 멈추고, Task는 이벤트 루프에서 스케줄링됩니다.

[asyncio 내부 동작 예시]
```python
async def hi(sleep_time, message):
    print(f"start {message}")
    print(asyncio.get_event_loop()._ready)      # 실행 대기 deque
    print(asyncio.get_event_loop()._scheduled)  # 미래 TimerHandle
    await asyncio.sleep(sleep_time)
    print(f"end {message}")
```

실행 순서:

asyncio.gather로 Task 등록 → _ready에 추가

await asyncio.sleep → Future가 _scheduled에 등록

Future 완료 시 _ready로 이동 → 실행 재개

출력에서 확인 가능:

_ready가 줄어드는 모습

_scheduled가 늘어나는 모습

완료 후 _scheduled에서 제거

[asyncio sleep 동작 구조]

hi(1)
hi(2)
hi(3)

| 시점          | \_ready    | \_scheduled                      |
| ----------- | ---------- | -------------------------------- |
| 초기          | 모든 Task 등록 | \[]                              |
| hi(1) await | 남은 Task    | TimerHandle(1초)                  |
| hi(2) await | 남은 Task    | TimerHandle(1초), TimerHandle(2초) |
| hi(1) 완료    | Task 제거    | 남은 TimerHandle                   |
| hi(2) 완료    | Task 제거    | 남은 TimerHandle                   |
| …           | …          | …                                |


즉시 실행 가능한 코루틴은 _ready에서 순차 실행

sleep 등의 대기 코루틴은 _scheduled에서 미래 시점에 _ready로 이동

[요약]

*코루틴(coroutine) : async def로 정의된 함수. #async 함수 + await

- await 지점에서 중단 가능 → 협력적 멀티태스킹(cooperative multitasking) 제공

*이벤트 루프(event loop) : 코루틴, 태스크, Future를 관리하는 OS 수준의 스케줄러

- 실행 가능한 작업을 _ready 큐에서 꺼냄.
네트워크, 디스크, DB 같은 I/O 요청은 OS 커널에 위임 → epoll, kqueue 사용
I/O 완료 시 _scheduled 큐에서 작업을 재개. 즉 CPU는 낭비 없이 사용 상태 유지

*Task는 Coroutine을 실행하기 위해 이벤트 루프에 등록한 객체

*Future는 나중에 값이 들어올 약속, await로 기다림

*Event Loop는 _ready와 _scheduled를 관리하며 코루틴 실행

*asyncio.gather로 여러 코루틴 병렬 처리 가능

*Generator와 유사하지만, asyncio는 이벤트 루프 중심으로 동작


[테스트 단위 전략]


(1) End-to-End 테스트 (E2E, API 테스트)

정의: 실제 API를 호출하여 유저 시나리오 전체를 테스트하는 방식

도구: httpx, self.client 등

장점 : 실제적 유저 경험을 재현,
여러 시스템을 아우르는 통합 검증 가능, 
한 번의 테스트로 많은 코드 경로를 커버

단점 : 느림 → 네트워크·DB·인증 등 여러 계층을 거치므로 속도가 떨어짐,
원인 파악 어려움 → 실패 시 어디서 문제가 발생했는지 찾기 힘듦,
플레이키(flaky) → 환경 의존적인 간헐적 실패 가능성 큼

(2) 단위 테스트 (Unit Test)

정의: 코드의 가장 작은 단위(함수, 서비스, 비즈니스 로직)를 개별적으로 검증하는 방식

장점 : 빠르다 → 작은 코드 조각만 실행,
신뢰성 높음 → 환경 요인에 영향 적음,
원인 파악 쉬움 → 어떤 함수/로직에서 문제인지 바로 알 수 있음,

단점 : 실제 사용자 시나리오를 충분히 커버하기 어려움,
내부 구현 변경 시 테스트 코드도 함께 깨질 가능성 있음

[테스트 피라미드]

하단: 단위 테스트(Unit Tests) → 가장 많아야 함 : 
- 코드 안정성을 높이고, 빠르게 실패 지점을 찾을 수 있음

중간: 통합 테스트(Integration Tests) : 
- 서비스, DB, 외부 API 등 컴포넌트 간 연동을 검증

상단: E2E 테스트 : 
- 가장 적어야 함. 실제 사용자 플로우를 검증하지만 비용과 유지보수 부담이 큼

원칙:
단위 테스트 > 통합 테스트 > E2E 테스트 순으로 개수를 구성하는 것이 “전통적으로” 건강한 구조

[최신 트랜드 — “E2E 중심 접근”]

왜 E2E를 중심으로?

데이터 검증 일관성 확보
→ API를 통한 데이터 생성 및 조회를 하면 항상 검증된 데이터만 다룸

내부 구현 변경에 강함
→ 함수 내부 로직이 바뀌어도, API 인터페이스가 동일하면 테스트 깨질 확률 낮음

테스트 커버리지 효율성
→ API 하나가 실행될 때 여러 계층의 코드를 자연스럽게 거침

성숙한 프로젝트에서는 안정성 높음
→ 안정화된 API에서는 실패보다 성공률이 높아 유지보수 부담 적음

[실무에서의 테스트 전략 제안]

Given: API 호출로 테스트 데이터 생성
When: API 호출로 동작 실행
Then: DB에 직접 접근하여 결과 검증

[결론]

프로젝트 초반 → 단위 테스트 비중 높게
→ 빠르게 문제 파악, 설계 안정화

프로젝트 성숙기 → E2E 테스트 비중 증가
→ 유지보수 효율성과 커버리지 극대화